---
title: Ликбез по AI инструментам ✨
hideInToc: true
---

# Ликбез по AI инструментам ✨

LLM в частности и Q&A сессия

<!--
- [ ] Начать запись
- [ ] Скинуть ссылки в чат
-->

---
hideInToc: true
---

# Кто Я

## Никонов Максим -  Senior Frontend Developer
Имею опыт использования различных AI тулов и не большой опыт работы с OpenAI API

@mnik01

<!-- 
- не эксперт
- могу ошибаться 
- основываюсь на источниках (ссылки в презентации)
-->

---
hideInToc: true
---

# Кто Вы

Для кого этот доклад?: В бОльшей степени для разработчиков (любого уровня), для мэнэджеров и HR специалистов в меньшей степени. Не будет грубокого погружения в код

<!-- входные знания особо не требуются -->

---
hideInToc: true
---

# Время и Регламент

- Займет N минут + M на Q&A
- Вопросы во время Q&A секций
- Легенда презентации: снизу номера страниц x/y, в teams сверху время сколько уже идёт мит

<Counter />

---
hideInToc: true
---

# План

<Toc columns="1" maxDepth="1"></Toc>

---

# Что такое AI инструменты и какие бывают?

AI тулы — это тулы которые используют AI

Это просто инструменты. Это не silver bullet от всех проблем. Но зная о существовании разных тулов в случае проблемы вы можете вспомнить про них и заюзать. (причем инструмент со своей спецификой: галлюцинации)

У инструментов есть задачи которые они решают, к некоторым задачам инструмент подойдет к некоторым нет.

Лучше всего работает там где вы можете пробовать + методом тыка и перебора найти решение, а не там где четко требуется с первого раза получить надежный результат.


AI (ИИ Иску́сственный интелле́кт) -- это широкое понятие включающее в себя много технологий и подходов (нейросети, LLMки, машинное обучение). 

---

Разделим AI тулы на 3 группы:

```mermaid
graph TD;
    AI-инструменты --> Видео ---> A[Sora];
    AI-инструменты --> Фото ---> B[Dall-e, Midjourney, StableDiffusion];
    AI-инструменты --> Текстовые ---> C[ChatGPT 3/4, Gemini, Copilot, Claude];
```

--- 

## Что такое LLM и какие бывают?

LLM это инструмент который генерирует текст в ответ на запрос пользователя (prompt)

Разобъём LLM на виды так:

```mermaid
graph TD;
    LLM --> A[текстовые];
    LLM --> B[текстовые+];
    LLM --> C[с интеграцией в кодовую базу];
```

Так или иначе они все сводятся к тексту (answer —> question)

---

<div class="flex gap-4">
  <div>
    <span>Текстовые</span>
    <img class="w-68" src="image.png"/>
  </div>

  <div class="flex flex-col gap-2">
    <span>Текстовые+</span>
    <span class="text-stone-500">web browsing, pdf reader, интеграции и т.д.</span>
    <img class="w-89" src="image-1.png"/>
  </div>
  
  <div class="flex flex-col gap-2">
    <span>Текстовые+</span>
    <span class="text-stone-500">web browsing, pdf reader, интеграции и т.д.</span>
    <img class="w-92" src="image-2.png"/>
  </div>
</div>

---

# Как работают LLMки

В сути LLM это 2 файла: файл с параметрами, который весит очень много и очень сложно добывается, и файл с кодом нейросети что бы генерировать ответы используя эти параметры.

<img class="w-62" src="image-3.png"/>

Эта модель может быть установлена на ваш компьютер локально и использоваться без интернета.

А можно и написать API и веб сервис для доступа к этим двум файлам. Так и работают веб-интерфейсы LLM'ок (chatgpt, gemini и тд)

--- 

### Как генерируется ответ
Нейросеть занимается предсказыванием наиболее вероятного следующего слова в предложении и его выдачей. Так она делает раз за разом выдавая новые слова (токены).

Предсказание того как слово будет следующим делается на основе параметров (весов) и контекста разговора.

--- 

### Что такое параметры

Вы можете думать о параметрах как о сжатом (с потерями) куске интернета. Берётся большой объём (10TB-100TB) текстов из интернета (reddit, stackoverflow и др.) и "сжимается" в 140 гигабайтный файл с весами (просто числа) для нейросети.

> На самом деле происходит не буквально сжатие. А всякая магия математики.

Это просто входные настройки модели. Чем больше параметров и чем они разнообразнее тем лучше (медленнее и дороже). И более того при большом объеме входных токенов и большом "контекстном окне" модели из-за эмерджентности обретают неожиданные свойства: способность переводить тексты, сочинять стихи, "мыслить", решать математические задачи.

> Из-за того что кусок интернета для тренировки модели был на английском преимущественно то и работать она будет лучше на английском

---

### Почему возникают галлюцинации

LLM'ка на выходе (после генерации параметров) уже не имеет всей информации об исходном куске интернета на котором ее тренировали, но умеет (настроена) прогнозировать следующее слово в последовательности.

<img class="w-152" src="image-6.png"/>

---


Поэтому она может не знать точно когда родилась Индира Ганди, но по форме предложения "понять" что надо подставить цифру:

```md
Q: Когда родилась Индира Ганди?
A: Индира Ганди родилась в 1917 году
```

Поэтому ответы LLMки чисто **вероятностные**, а не точные. И могут выдавать совершенно не логичные ответы по той или иной причине:

<img class="w-82" src="image-5.png"/>

---

# Как это всё применять?

---

# Privacy and security concerns

---

# Бонус: лайфхаки как составлять промпты

---

# Q&A

@mnik01